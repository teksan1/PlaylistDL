#!/usr/bin/env python3
import json
import os
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from queue import Queue
import subprocess
import re
from rapidfuzz import fuzz

# ----------------- Config -----------------
MAX_THREADS = 8
SAVE_JSON = True
OUTPUT_FILE = Path(__file__).parent / "youtube_urls.json"

# Example track list
TRACKS = [
    "Rhythm Is Rhythm ‚Äì Icon (Transmat)",
    "Esser‚Äôay ‚Äì Forces ‚ÄòReese Mix‚Äô (KMS)",
    "E-Dancer ‚Äì Pump The Move (KMS)",
    "Outlander -The Vamp ‚ÄòKevin Saunderson Remix‚Äô (R&S)",
    "E-Dancer ‚Äì World of Deep (KMS)",
    "Slam ‚Äì Positive Education (Soma)",
    "Lemon 8 ‚Äì Model 8 ‚ÄòLemon 8 Remix‚Äô (Basic Energy)",
    "Robert Armani ‚Äì Circus Bells ‚ÄòRemixed By Hardfloor‚Äô (Djax -Up-Beats)",
    "FEOS vs M/S/O ‚Äì Into The Groove (Ongaku)",
    "Ian Pooley ‚Äì Chord Memory (Force Inc.)",
    "DJ Gilb-R ‚Äì Pressure ‚ÄòLaurentlaboratoiral'ancienne Mix‚Äô (Versatile)",
    "Dot Allison ‚Äì We‚Äôre Only Science ‚ÄòSlam Remix‚Äô (Mantra)",
    "Adam Beyer ‚Äì Remainings III ‚ÄòDK Remix 1‚Äô (Drumcode)",
    "Green Velvet ‚Äì Land Of The Lost ‚ÄòIan Pooley‚Äôs Infected Mix‚Äô (Music Man)",
    "Black Water ‚Äì Black Water (430 Wes)"
]

# ----------------- Functions -----------------
def search_youtube(track_name):
    try:
        result = subprocess.run(
            ["yt-dlp", f"ytsearch20:{track_name}", "--dump-json", "--skip-download", "--no-playlist"],
            capture_output=True,
            text=True,
            check=True
        )
        best_match = None
        highest_ratio = -1
        for line in result.stdout.splitlines():
            data = json.loads(line)
            title = data.get("title", "")
            url = data.get("webpage_url", "")
            ratio = fuzz.ratio(track_name.lower(), title.lower())
            if ratio > highest_ratio:
                highest_ratio = ratio
                best_match = url
        return best_match
    except Exception as e:
        print(f"‚ùå Failed to find {track_name}: {e}")
        return None

def worker(queue, output):
    while True:
        try:
            track = queue.get_nowait()
        except:
            break
        url = search_youtube(track)
        output[track] = url
        print(f"‚úÖ {track}: {url}")
        queue.task_done()

# ----------------- Main -----------------
def main():
    q = Queue()
    for track in TRACKS:
        q.put(track)

    results = {}
    threads = []
    for _ in range(min(MAX_THREADS, len(TRACKS))):
        t = ThreadPoolExecutor(max_workers=1).submit(worker, q, results)
        threads.append(t)

    q.join()

    if SAVE_JSON:
        with open(OUTPUT_FILE, "w") as f:
            json.dump(results, f, indent=2)
        print(f"\nüíæ Saved JSON to {OUTPUT_FILE}")

if __name__ == "__main__":
    main()
